[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Our Course Project",
    "section": "",
    "text": "I’m honored to be a member of the DataVizards project team.\nBelow, you’ll find a brief summary of our project. To access a detailed project description, please go to https://[https://emu-hacettepe-analytics.github.io/emu430-fall2023-team-data_vizards/].\nSummary\nWe will carry out our project by considering 2021 internal migration data across Türkiye. Our main focus is In Migration of internal cities. In this regard, migration trends between different regions such as Eastern Anatolia, Southeastern Anatolia, Aegean, Marmara will be determined and migration relations between big cities and other cities will be analyzed in detail. The relationship between population density and migration will be determined by examining migration rates, especially in cities with large populations. Migration trends will be evaluated according to age groups, gender, educational status and reasons for migration. (retirement, appointment, etc.) Also, the economic development level of the economic region will be interpreted according to the labor force, household disposable income, number of enterprises, number of housing sales, etc. This comprehensive analysis will guide our project in understanding Turkey's migration situation.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello! My name is Melek Er.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "library(tidyverse) \nlibrary(rvest) \nlibrary(stringr) \n\n# Define the URL\nurl_2010_2023 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250\"\nurl_before_2009 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"\n\nall_urls &lt;- c(url_2010_2023, url_before_2009)\nmovie_data &lt;- data.frame()\nfor (url in all_urls) {\n  data_html &lt;- read_html(url)\n\n  title_names &lt;- data_html |&gt; html_nodes('.ipc-title__text')\n  title_names &lt;- html_text(title_names)\n  title_names &lt;- tail(head(title_names,-1),-1)\n  title_names &lt;- str_split(title_names, \" \", n=2)\n  title_names &lt;- unlist(lapply(title_names, function(x) {x[2]}))\n\n  year_values &lt;- data_html |&gt; html_nodes('.dli-title-metadata-item:nth-child(1)')\n  year_values &lt;- html_text(year_values)\n  year_values &lt;- str_remove_all(year_values, \"[()]\")\n  year_values &lt;- as.numeric(year_values)\n  \n  duration_values &lt;- data_html |&gt; html_nodes('.dli-title-metadata-item:nth-child(2)')\n  duration_values &lt;- html_text(duration_values)\n  duration_values &lt;- 60*as.numeric(substr(duration_values,1,1))+ifelse(nchar(duration_values)&gt;2,as.integer(substring(duration_values,nchar(duration_values)-2,nchar(duration_values)-1)),0)\n  \n  rating_values &lt;- data_html %&gt;% html_nodes('.ratingGroup--imdb-rating') %&gt;% html_text() %&gt;%\n  str_match(\"\\\\b([0-9]+\\\\.[0-9]+)\") %&gt;% as.numeric() # I write str_match(\"\\\\b([0-9]+\\\\.[0-9]+)\") line of code with the help of AI \n  \n  vote_values &lt;- data_html |&gt;  html_nodes(\".kRnqtn\")\n  vote_values &lt;- html_text(vote_values)\n  vote_values &lt;- str_remove_all(vote_values, \"[a-zA-Z,]\") \n  vote_values &lt;- as.numeric(vote_values)\n  \n  temp_data &lt;- data.frame(Title = title_names,\n                          Year = year_values,\n                          Duration = duration_values,\n                          Rating = rating_values,\n                          Votes = vote_values)\n  \n  temp_data &lt;- unique(temp_data)\n  movie_data &lt;- rbind(movie_data, temp_data)\n}\n\n# a) \n\n# It ranks the movies from the highest rated movie to the lowest rated movie and shows the 5 highest rated movies.\nmovie_data %&gt;% arrange(desc(Rating)) %&gt;% head(5) \n\n                         Title Year Duration Rating Votes\n1               Hababam Sinifi 1975       87    9.2 42513\n2       CM101MMXI Fundamentals 2013      139    9.1 46996\n3                   Tosun Pasa 1976       90    8.9 24329\n4 Hababam Sinifi Sinifta Kaldi 1975       95    8.9 24370\n5                Süt Kardesler 1976       80    8.8 20888\n\n# It sorts the movie from the highest rated movie to the lowest rated movie and shows the 5 lowest rated movies.\nmovie_data %&gt;% arrange(desc(Rating)) %&gt;% tail(5) \n\n                             Title Year Duration Rating Votes\n466                 Cumali Ceber 2 2018      100    1.2 10229\n467                          Müjde 2022      288    1.2  9920\n468              15/07 Safak Vakti 2021       95    1.2 20608\n469 Cumali Ceber: Allah Seni Alsin 2017      100    1.0 39267\n470                           Reis 2017      108    1.0 73973\n\n# In my opinion, the highest-rated movies include dramatic and emotional movies, while the lowest-rated movies include comedies movies. This shows that Turkish audiences value dramatic films more than comedy films. Additionally, Recep İvedik (2008), the first movie of the Recep İvedik series, has a much higher score with 4.8 points. This suggests that the quality of sequels has decreased or that audiences have become bored with such films.\n\n#b)\n\n# My favorite movies are Kuru Otlar Üstüne and Kelebekler.\nmovie_data %&gt;% filter(Title == \"Kuru Otlar Üstüne\")\n\n              Title Year Duration Rating Votes\n1 Kuru Otlar Üstüne 2023      197    8.1  5081\n\nmovie_data %&gt;% filter(Title == \"Kelebekler\")\n\n       Title Year Duration Rating Votes\n1 Kelebekler 2018      117    7.3 15778\n\n#c\n\n# Calculate the yearly mean ratings and counts\nyearly_stats &lt;- movie_data %&gt;% \n  group_by(Year) %&gt;% \n  summarise(mean_rating = mean(Rating), count = n())\n\n# Plot the yearly mean ratings\nggplot(yearly_stats, aes(x = Year, y = mean_rating)) +\n  geom_point() +\n  labs(title = \"Yearly Mean Ratings of Turkish Movies\",\n       x = \"Year\",\n       y = \"Mean Rating\")\n\n\n\n# Plot the yearly counts\nggplot(yearly_stats, aes(x = Year, y = count)) +\n  geom_point() +\n  labs(title = \"Yearly Counts of Turkish Movies\",\n       x = \"Year\",\n       y = \"Count\")\n\n\n\n# It can be seen how the average scores and number of films of Turkish films change over the years. Some observations are as follows: -The average scores of Turkish films decreased after 2010 and reached the lowest level in 2023. -The number of Turkish films started to increase after 2010 and reached the highest level in 2023-There seems to be a negative relationship between the average scores of Turkish films and their numbers. That is, as the number of movies increases, the average score decreases.\n\n# Plot the box plot of ratings by year\nggplot(movie_data, aes(x = Year, y = Rating)) +\n  geom_boxplot() +\n  labs(title = \"Box Plot of Ratings of Turkish Movies by Year\",\n       x = \"Year\",\n       y = \"Rating\")\n\n\n\n#It can be seen how the scores of Turkish films change over the years, in which years they received higher or lower scores, and in which years there is more or less variation. Some observations are as follows: -The median of the scores of Turkish films decreased after 2010 and reached the lowest level in 2023. -The quarters of the scores of Turkish films narrowed after 2010 and reached the narrowest level in 2023. This shows that the scores of the films are more homogeneous. -The outliers in the scores of Turkish films decreased after 2010 and decreased to almost none in 2023. This indicates that the scores for the films are more normally distributed.\n\n#d)\n\ncor(movie_data$Votes, movie_data$Rating) \n\n[1] 0.1307806\n\n# Returns the correlation coefficient between the number of votes and the score. Since it is a value close to 0, we can say that there is no relationship, that is, there is no connection between the number of votes and the score. Since the value is close to zero, we can say that there is a weak positive relationship between the number of votes and the score. So, we can say that as the number of votes increases, the score also increases slightly. However, this relationship is not very strong.\n\n\n#e\n\ncor(movie_data$Duration, movie_data$Rating) \n\n[1] -0.03192943\n\n#Since the value is close to zero, we can say that there is a weak positive relationship between the number of votes and the score. So, we can say that as the number of votes increases, the score also increases slightly. However, this relationship is not very strong.\n\n# Define the URL\nurl_top_1000 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&sort=moviemeter,asc&groups=top_1000&country_of_origin=TR\"\n\n# Read the HTML data\ndata_html &lt;- read_html(url_top_1000)\n\n# Extract the title names\ntitle_names &lt;- data_html |&gt; html_nodes('.ipc-title__text')\ntitle_names &lt;- html_text(title_names)\ntitle_names &lt;- tail(head(title_names,-1),-1)\ntitle_names &lt;- str_split(title_names, \" \", n=2)\ntitle_names &lt;- unlist(lapply(title_names, function(x) {x[2]}))\n\n# Extract the year values\nyear_values &lt;- data_html |&gt; html_nodes('.dli-title-metadata-item:nth-child(1)')\nyear_values &lt;- html_text(year_values)\nyear_values &lt;- str_remove_all(year_values, \"[()]\")\nyear_values &lt;- as.numeric(year_values)\n\n# Create the data frame\ntop_1000_data &lt;- data.frame(Title = title_names, Year = year_values)\n\n# Join the two data frames by title\ntop_1000_data &lt;- inner_join(movie_data, top_1000_data, by = \"Title\")\n\n# Arrange the data frame by rating in descending order\nmovie_data %&gt;% arrange(desc(Rating)) %&gt;% head(11)\n\n                          Title Year Duration Rating Votes\n1                Hababam Sinifi 1975       87    9.2 42513\n2        CM101MMXI Fundamentals 2013      139    9.1 46996\n3                    Tosun Pasa 1976       90    8.9 24329\n4  Hababam Sinifi Sinifta Kaldi 1975       95    8.9 24370\n5                 Süt Kardesler 1976       80    8.8 20888\n6              Saban Oglu Saban 1977       90    8.7 18535\n7                    Zügürt Aga 1985      101    8.7 16135\n8                 Neseli Günler 1978       95    8.7 11807\n9                   Kibar Feyzo 1978       83    8.7 17128\n10      Hababam Sinifi Uyaniyor 1976       94    8.7 20640\n11               Canim Kardesim 1973       85    8.6 10097\n\nprint(top_1000_data)\n\n                       Title Year.x Duration Rating Votes Year.y\n1   Yedinci Kogustaki Mucize   2019      132    8.2 54161   2019\n2                 Kis Uykusu   2014      196    8.0 54642   2014\n3  Ayla: The Daughter of War   2017      125    8.3 42991   2017\n4                Ahlat Agaci   2018      188    8.0 27011   2018\n5    Bir Zamanlar Anadolu'da   2011      157    7.8 49359   2011\n6      Nefes: Vatan Sagolsun   2009      128    8.0 35020   2009\n7             Babam ve Oglum   2005      108    8.2 91035   2005\n8                     Eskiya   1996      128    8.1 71703   1996\n9                   G.O.R.A.   2004      127    8.0 66032   2004\n10                 Vizontele   2001      110    8.0 38402   2001\n11  Her Sey Çok Güzel Olacak   1998      107    8.1 27122   1998\n\n#The first 11 movies in the top_1000_data data frame are not the same as the first 11 movies in the movie_data data frame. This means that IMDb determines the top 1000 movie list not only based on ratings but also other factors such as number of movie views, country, genre, etc.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "B.S., Industrial Engineering, Hacettepe University, Turkey, 2023 - ongoing."
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nFirm TUBITAK BILGEM YTE, Candidate Researcher, year 2023 -ongoing."
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nFirm Ford Otosan, position Human Resources, year 2022\nFirm Wicode, position Digital Marketing, year 2022\nFirm TUBITAK BILGEM YTE, position Business Analyst, year 2023\nFirm Papilon Savunma, position Sales, year 2023"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "#https://www.rstudio.com/conference/2022/talks/achieving-seamless-workflow-r-python/\nBrief Summary\nStatistics Canada is the official statistical agency of Canada, and it is a large institution with over 6,000 employees. It has a legal obligation to ensure the privacy of personal information, which is why it has implemented an internal system called G-Confid to prevent the disclosure of confidential information, and this system is exclusively implemented using the SAS programming language. As a result, many analysts and data scientists at Statistics Canada are required to use the SAS programming language as part of their workflow. Therefore, finding ways to seamlessly work between open-source programming languages and SAS is of utmost importance. Melissa offers a solution to create a harmonious workflow for R, Python, and SAS within RStudio. This approach provides a recipe that will help both data scientists and analysts effectively perform their tasks."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g. Fall 2023] EMU 430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\nThe most recent update to this page was made on October 25, 2023\n\n\n\n Back to top"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "",
    "text": "#https://www.rstudio.com/conference/2022/talks/achieving-seamless-workflow-r-python/\nBrief Summary\nStatistics Canada is the official statistical agency of Canada, and it is a large institution with over 6,000 employees. It has a legal obligation to ensure the privacy of personal information, which is why it has implemented an internal system called G-Confid to prevent the disclosure of confidential information, and this system is exclusively implemented using the SAS programming language. As a result, many analysts and data scientists at Statistics Canada are required to use the SAS programming language as part of their workflow. Therefore, finding ways to seamlessly work between open-source programming languages and SAS is of utmost importance. Melissa offers a solution to create a harmonious workflow for R, Python, and SAS within RStudio. This approach provides a recipe that will help both data scientists and analysts effectively perform their tasks."
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "(b)",
    "text": "(b)"
  },
  {
    "objectID": "assignments/assignment-1.html#c",
    "href": "assignments/assignment-1.html#c",
    "title": "Assignment 1",
    "section": "(c)",
    "text": "(c)\n\nlibrary(\"dslabs\")\ndata(\"na_example\")\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\nsum(is.na(na_example))\n\n[1] 145\n\nnew_na_example &lt;- na_example\nnew_na_example[is.na(new_na_example)] &lt;- 0\nprint(new_na_example)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 0 2 2 1 4 0 1 1 2 1 2 2 1 2 5 0 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 0 0 0 1 1 5 1 3 1 0 4 4 7 3 2 0 0 1 0 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 0 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 0 4 3 4 3 1 2 1 0 0 0 0 1 5 1 2 1 3 5 3 2 2 0 0 0 0 3 5 3 1 1 4\n [149] 2 4 3 3 0 2 3 2 6 0 1 1 2 2 1 3 1 1 5 0 0 2 4 0 2 5 1 4 3 3 0 4 3 1 4 1 1\n [186] 3 1 1 0 0 3 5 2 2 2 3 1 2 2 3 2 1 0 2 0 1 0 0 2 1 1 0 3 0 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 0 5 1 4 0 3 0 0 1 1 5 2 3 3 2 4 0 3 2 5 0 2 3\n [260] 4 6 2 2 2 0 2 0 2 0 3 3 2 2 4 3 1 4 2 0 2 4 0 6 2 3 1 0 2 2 0 1 1 3 2 3 3\n [297] 1 0 1 4 2 1 1 3 2 1 2 3 1 0 2 3 3 2 1 2 3 5 5 1 2 3 3 1 0 0 1 2 4 0 2 1 1\n [334] 1 3 2 1 1 3 4 0 1 2 1 1 3 3 0 1 1 3 5 3 2 3 4 1 4 3 1 0 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 0 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 0 3 3 0 2 0 1 2 1 1 4 2 1 4 4 0\n [408] 1 2 0 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 0 4 4 4 1 1 0 4\n [445] 3 0 1 3 1 3 2 4 2 2 2 3 2 1 4 3 0 1 4 3 1 3 2 0 3 0 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 0 3 2 1 1 2 0 2 2 2 3 3 1 1 2 0 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 0 1 4 1 2 4 1 3 2 0 1 1 0 2 1 1 4 2 3 3 1 5 3 1 1 2 0 1 1\n [556] 3 1 3 2 4 0 2 3 2 1 2 1 1 1 2 2 3 1 5 2 0 2 0 3 2 2 2 1 5 3 2 3 1 0 3 1 2\n [593] 2 2 1 2 2 4 0 6 1 2 0 1 1 2 2 3 0 3 2 3 3 4 2 0 2 0 4 0 1 1 2 2 3 1 1 1 3\n [630] 0 2 5 0 7 1 0 4 3 3 1 0 1 1 1 1 3 2 4 2 2 3 0 0 1 4 3 2 2 2 3 2 4 2 2 4 0\n [667] 0 0 6 3 3 1 4 4 2 1 0 1 6 0 3 3 2 1 1 6 0 1 5 1 0 2 6 2 0 4 1 3 1 2 0 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 0 1 2 2 2 2 4 5 0 0 0 4 3 3 3\n [741] 2 4 2 4 0 0 0 0 2 1 0 2 4 3 2 0 2 3 1 3 4 0 1 2 1 2 0 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 0 0 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 0 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 0 1 3 1 2 0 1 2 1 2 1 0 1 3 2 3 2 0 2 1 4 2 0 0 0 2 4 2 0 0 3\n [852] 1 0 5 5 2 2 2 0 2 1 3 1 3 2 4 2 4 0 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 0 3\n [889] 3 2 2 0 0 3 2 1 2 4 1 1 1 1 4 3 2 0 3 2 0 1 0 3 2 1 1 1 2 0 2 2 3 3 2 0 0\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 0 1 1 1 0 4 3 5 1 1 2 0 2 2 2 2 5 2 2 3 1 2 3 0\n [963] 1 2 0 0 2 0 3 1 1 2 5 3 5 1 1 4 0 2 1 3 1 1 2 4 3 3 3 0 1 1 2 2 1 1 2 2 0\n[1000] 2\n\nsum(is.na(new_na_example))\n\n[1] 0"
  }
]